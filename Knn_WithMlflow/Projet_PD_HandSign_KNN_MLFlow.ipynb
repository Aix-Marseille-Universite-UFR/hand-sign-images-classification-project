{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Using cached mlflow-2.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting mlflow-skinny==2.18.0 (from mlflow)\n",
      "  Using cached mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting Flask<4 (from mlflow)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Using cached alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from mlflow) (3.9.3)\n",
      "Requirement already satisfied: numpy<3 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from mlflow) (2.1.3)\n",
      "Collecting pandas<3 (from mlflow)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting pyarrow<19,>=4.0.0 (from mlflow)\n",
      "  Using cached pyarrow-18.1.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from mlflow) (1.14.1)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow)\n",
      "  Using cached SQLAlchemy-2.0.36-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting Jinja2<4,>=2.11 (from mlflow)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached databricks_sdk-0.38.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging<25 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
      "Collecting protobuf<6,>=3.12.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached protobuf-5.29.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pyyaml<7,>=5.1 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached sqlparse-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4 (from alembic!=1.10.0,<2->mlflow)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Collecting Werkzeug>=3.1 (from Flask<4->mlflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.2 (from Flask<4->mlflow)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from Flask<4->mlflow)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2<4,>=2.11->mlflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from matplotlib<4->mlflow) (4.55.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Collecting pytz>=2020.1 (from pandas<3->mlflow)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3->mlflow)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nedday/Documents/All Projects /hand-sign-images-classification-project/hand-sign-images-classification-project/.venv/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached wrapt-1.17.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached mlflow-2.18.0-py3-none-any.whl (27.3 MB)\n",
      "Using cached mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\n",
      "Using cached alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached pyarrow-18.1.0-cp313-cp313-macosx_12_0_arm64.whl (29.5 MB)\n",
      "Using cached SQLAlchemy-2.0.36-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached databricks_sdk-0.38.0-py3-none-any.whl (575 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "Using cached protobuf-5.29.1-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached sqlparse-0.5.2-py3-none-any.whl (44 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "Using cached Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Using cached wrapt-1.17.0-cp313-cp313-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pytz, zipp, wrapt, tzdata, typing-extensions, sqlparse, smmap, pyyaml, pyasn1, pyarrow, protobuf, MarkupSafe, markdown, itsdangerous, gunicorn, graphql-core, cloudpickle, click, cachetools, blinker, Werkzeug, sqlalchemy, rsa, pyasn1-modules, pandas, Mako, Jinja2, importlib-metadata, graphql-relay, gitdb, docker, deprecated, opentelemetry-api, graphene, google-auth, gitpython, Flask, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "Successfully installed Flask-3.1.0 Jinja2-3.1.4 Mako-1.3.8 MarkupSafe-3.0.2 Werkzeug-3.1.3 alembic-1.14.0 blinker-1.9.0 cachetools-5.5.0 click-8.1.7 cloudpickle-3.1.0 databricks-sdk-0.38.0 deprecated-1.2.15 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.36.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 importlib-metadata-8.5.0 itsdangerous-2.2.0 markdown-3.7 mlflow-2.18.0 mlflow-skinny-2.18.0 opentelemetry-api-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 pandas-2.2.3 protobuf-5.29.1 pyarrow-18.1.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pytz-2024.2 pyyaml-6.0.2 rsa-4.9 smmap-5.0.1 sqlalchemy-2.0.36 sqlparse-0.5.2 typing-extensions-4.12.2 tzdata-2024.2 wrapt-1.17.0 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1SkrU6WIElM",
    "outputId": "226ce484-00d6-465b-a1e0-af567989d4b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/mohamed-amine_kenzeddine/Downloads/testmlflow/mlruns/382260133435030118', creation_time=1733776805799, experiment_id='382260133435030118', last_update_time=1733776805799, lifecycle_stage='active', name='hand_sign_classifier', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow\n",
    "mlflow.set_experiment(\"hand_sign_classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhMnnftQg2WN",
    "outputId": "0d813500-372f-415c-c6c4-11e4a2b3c802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/mohamed-amine_kenzeddine/.cache/kagglehub/datasets/furkanakdeniz/asl-handsign-dataset-grayscaled-thresholded/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"furkanakdeniz/asl-handsign-dataset-grayscaled-thresholded\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RKnVTz5IfrCV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # Pour redimensionner les images\n",
    "\n",
    "# Chemin vers le dataset\n",
    "dataset_path = \"/Users/mohamed-amine_kenzeddine/.cache/kagglehub/datasets/furkanakdeniz/asl-handsign-dataset-grayscaled-thresholded/versions/1/asl-dataset/asl-dataset/\"\n",
    "\n",
    "# Alphabets disponibles dans le dataset\n",
    "alphabet_array = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "# Charger les images et leurs étiquettes\n",
    "image_arr = []\n",
    "image_name_value = []\n",
    "\n",
    "# Taille cible pour toutes les images\n",
    "target_size = (28, 28)\n",
    "\n",
    "for letter in alphabet_array:\n",
    "    path_letter = os.path.join(dataset_path, \"train\", letter)\n",
    "    if not os.path.exists(path_letter):\n",
    "        print(f\"Le dossier {path_letter} n'existe pas.\")\n",
    "        continue\n",
    "\n",
    "    for image_name in os.listdir(path_letter):\n",
    "        image_path = os.path.join(path_letter, image_name)\n",
    "        # Charger et redimensionner l'image\n",
    "        image = plt.imread(image_path)  # Charger l'image\n",
    "        if image.ndim == 3:  # Convertir en niveau de gris si l'image est RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        resized_image = cv2.resize(image, target_size)  # Redimensionner\n",
    "        image_arr.append(resized_image.flatten())  # Aplatir et ajouter à la liste\n",
    "        image_name_value.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YryZVOvOf8IW"
   },
   "outputs": [],
   "source": [
    "# Conversion en tableaux numpy\n",
    "X_data = np.array(image_arr)\n",
    "y_data = np.array(image_name_value)\n",
    "\n",
    "# Créer un mapping des étiquettes vers des entiers\n",
    "label_to_int = {label: idx for idx, label in enumerate(np.unique(y_data))}\n",
    "y_data = np.array([label_to_int[label] for label in y_data])\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MRwq1uG5KY-6",
    "outputId": "4388d16c-2938-4252-e047-a52ff95c2c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_0 started with n_neighbors=3, weights=uniform, metric=euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:05:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_0 completed with accuracy=0.9874, precision=0.9876. Execution time: 23.38 seconds.\n",
      "Run Version_1 started with n_neighbors=3, weights=uniform, metric=manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:07:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_1 completed with accuracy=0.9837, precision=0.9840. Execution time: 124.42 seconds.\n",
      "Run Version_2 started with n_neighbors=3, weights=distance, metric=euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:07:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_2 completed with accuracy=0.9902, precision=0.9903. Execution time: 10.59 seconds.\n",
      "Run Version_3 started with n_neighbors=3, weights=distance, metric=manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:09:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_3 completed with accuracy=0.9877, precision=0.9879. Execution time: 107.59 seconds.\n",
      "Run Version_4 started with n_neighbors=5, weights=uniform, metric=euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:09:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_4 completed with accuracy=0.9779, precision=0.9784. Execution time: 21.33 seconds.\n",
      "Run Version_5 started with n_neighbors=5, weights=uniform, metric=manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:12:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_5 completed with accuracy=0.9729, precision=0.9737. Execution time: 153.05 seconds.\n",
      "Run Version_6 started with n_neighbors=5, weights=distance, metric=euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:12:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_6 completed with accuracy=0.9844, precision=0.9847. Execution time: 23.59 seconds.\n",
      "Run Version_7 started with n_neighbors=5, weights=distance, metric=manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:14:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_7 completed with accuracy=0.9817, precision=0.9822. Execution time: 112.08 seconds.\n",
      "Run Version_8 started with n_neighbors=7, weights=uniform, metric=euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:15:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_8 completed with accuracy=0.9692, precision=0.9703. Execution time: 12.97 seconds.\n",
      "Run Version_9 started with n_neighbors=7, weights=uniform, metric=manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:18:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_9 completed with accuracy=0.9649, precision=0.9662. Execution time: 171.58 seconds.\n",
      "Run Version_10 started with n_neighbors=7, weights=distance, metric=euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:18:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_10 completed with accuracy=0.9784, precision=0.9789. Execution time: 15.78 seconds.\n",
      "Run Version_11 started with n_neighbors=7, weights=distance, metric=manhattan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:20:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Version_11 completed with accuracy=0.9765, precision=0.9772. Execution time: 135.53 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Configurer MLflow pour stocker les logs localement\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "\n",
    "# Paramètres à tester dans GridSearch\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Générer toutes les combinaisons possibles de paramètres\n",
    "param_combinations = list(itertools.product(\n",
    "    param_grid['n_neighbors'],\n",
    "    param_grid['weights'],\n",
    "    param_grid['metric']\n",
    "))\n",
    "\n",
    "# Variables pour suivre le meilleur modèle\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_params = {}\n",
    "i = 0\n",
    "\n",
    "# Boucle sur chaque combinaison de paramètres\n",
    "for params in param_combinations:\n",
    "    n_neighbors, weights, metric = params\n",
    "    with mlflow.start_run(run_name=f\"Version_{i}\") as run:\n",
    "        # Ajouter un tag avec le numéro de version\n",
    "        mlflow.set_tag(\"version\", f\"Version_{i}\")\n",
    "        mlflow.set_tag(\"model_type\", \"KNeighborsClassifier\")\n",
    "\n",
    "\n",
    "        # Entraînement du modèle\n",
    "        start_time = time.time()\n",
    "        print(f\"Run Version_{i} started with n_neighbors={n_neighbors}, weights={weights}, metric={metric}\")\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        execution_time = time.time() - start_time\n",
    "\n",
    "        # Enregistrement du modèle\n",
    "        mlflow.sklearn.log_model(model, \"KNN\")\n",
    "\n",
    "        # Calcul des métriques\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "        mlflow.log_params({'n_neighbors': n_neighbors, 'weights': weights, 'metric': metric})\n",
    "        mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"execution_time\", execution_time)\n",
    "\n",
    "        # Sauvegarder le modèle pour chaque run\n",
    "        #model_filename = f\"knn_model_version_{i}.pkl\"\n",
    "        #joblib.dump(model, model_filename)\n",
    "        #mlflow.log_artifact(model_filename)\n",
    "\n",
    "        # Vérifier si ce modèle est le meilleur\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_params = {'n_neighbors': n_neighbors, 'weights': weights, 'metric': metric}\n",
    "\n",
    "        print(f\"Run Version_{i} completed with accuracy={accuracy:.4f}, precision={precision:.4f}. Execution time: {execution_time:.2f} seconds.\")\n",
    "        i += 1  # Incrémenter la version\n",
    "\n",
    "# Sauvegarder le meilleur modèle\n",
    "#best_model_filename = \"knn_best_model.pkl\"\n",
    "#joblib.dump(best_model, best_model_filename)\n",
    "#print(f\"Meilleur modèle sauvegardé sous : {best_model_filename}\")\n",
    "\n",
    "# Télécharger le répertoire MLflow pour une visualisation locale\n",
    "#print(\"Compression des logs MLflow...\")\n",
    "#!zip -r mlruns.zip /content/mlruns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage model versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/09 22:46:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle est enregistré sous le nom 'KNN_Model' avec la version 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'KNN_Model'.\n",
      "Created version '1' of model 'KNN_Model'.\n",
      "/var/folders/zk/pf_lp1yn7wd1lbr8mwy593rc0000gn/T/ipykernel_23631/2568249302.py:27: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Nom unique pour le modèle dans le registre\n",
    "model_name = \"KNN_Model\"\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "client = MlflowClient()\n",
    "\n",
    "# Démarrer une nouvelle session MLflow pour le meilleur modèle\n",
    "with mlflow.start_run(run_name=\"Best_Model_Registration\") as run:\n",
    "    # Loguer le meilleur modèle dans cette nouvelle session\n",
    "    mlflow.sklearn.log_model(best_model, \"best_knn_model\")\n",
    "\n",
    "    # Enregistrement dans le Model Registry\n",
    "    model_uri = f\"runs:/{run.info.run_id}/best_knn_model\"\n",
    "    registered_model = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "    # Ajouter une description au modèle\n",
    "    client.update_registered_model(\n",
    "        name=model_name,\n",
    "        description=\"KNN Classifier trained on hand sign dataset with optimized hyperparameters.\",\n",
    "    )\n",
    "\n",
    "    # Ajouter une version et un tag\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=registered_model.version,\n",
    "        stage=\"Production\",  # ou \"Staging\" si besoin\n",
    "    )\n",
    "\n",
    "    print(f\"Le modèle est enregistré sous le nom '{model_name}' avec la version {registered_model.version}.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zhGLvTp2P44B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction (lettre) : V\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Fonction pour convertir un numéro en lettre de l'alphabet\n",
    "def number_to_letter(number):\n",
    "    # Vérifier que le nombre est dans la plage de 1 à 24 (pour les lettres de A à Z)\n",
    "    if 1 <= number <= 24:\n",
    "        return chr(64 + number)  # 'A' est le caractère ASCII 65, donc 64 + number donne la lettre\n",
    "    else:\n",
    "        return None  # Gérer les cas où le numéro dépasse 24\n",
    "\n",
    "# Supposons que 'X_test' contient des images\n",
    "sample_image = X_test[0]  # Sélection de la première image\n",
    "\n",
    "# Convertir l'image en liste pour la sérialisation JSON\n",
    "input_data = {\n",
    "    \"inputs\": [sample_image.tolist()]  # Ajouter des crochets pour obtenir un tableau 4D\n",
    "}\n",
    "\n",
    "# URL de l'API REST (Assurez-vous que le serveur est bien lancé)\n",
    "url = \"http://127.0.0.1:8989/invocations\"  # Point de terminaison correct pour les prédictions\n",
    "\n",
    "# Envoi de la requête POST\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(input_data))\n",
    "\n",
    "# Affichage du résultat de la prédiction\n",
    "if response.status_code == 200:\n",
    "    prediction = response.json()\n",
    "    predicted_number = prediction['predictions'][0]  # Récupérer le premier élément de la prédiction\n",
    "    predicted_letter = number_to_letter(predicted_number)  # Convertir en lettre\n",
    "    print(\"Prédiction (lettre) :\", predicted_letter)\n",
    "else:\n",
    "    print(\"Erreur :\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
